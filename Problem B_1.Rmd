---
title: "Problem B.1"
author: "Haonan LI"
date: "2025-03-20"
output: pdf_document

---

```{r setup, include=FALSE}
Sys.setenv(LANG = "en")
knitr::opts_chunk$set(echo = TRUE)
```

```{r cars}
# (a)
library(ISLR)

# Load Auto Data
data(Auto)

# information about the dataset
head(Auto)
summary(Auto)

# Handling of possible missing values
Auto <- na.omit(Auto)

# Calculate the median mpg
mpg_median <- median(Auto$mpg)
mpg_median

# Create binary variable mpg01
mpg01 <- ifelse(Auto$mpg > mpg_median, 1, 0)

# Add mpg01 to Auto dataset
Auto$mpg01 <- mpg01

# View new data frame
head(Auto)
summary(Auto$mpg01)

# (b)
# Split the drawing window into 2 rows and 3 columns
par(mfrow=c(2,3))

# horsePower vs mpg01
boxplot(horsepower ~ mpg01, data=Auto,
        main="Horsepower by mpg01",
        xlab="mpg01", ylab="Horsepower")

# weight vs mpg01
boxplot(weight ~ mpg01, data=Auto,
        main="Weight by mpg01",
        xlab="mpg01", ylab="Weight")

# displacement vs mpg01
boxplot(displacement ~ mpg01, data=Auto,
        main="Displacement by mpg01",
        xlab="mpg01", ylab="Displacement")

# acceleration vs mpg01
boxplot(acceleration ~ mpg01, data=Auto,
        main="Acceleration by mpg01",
        xlab="mpg01", ylab="Acceleration")

# year vs mpg01
boxplot(year ~ mpg01, data=Auto,
        main="Year by mpg01",
        xlab="mpg01", ylab="Year")

# cylinders vs mpg01
boxplot(cylinders ~ mpg01, data=Auto,
        main="Cylinders by mpg01",
        xlab="mpg01", ylab="Cylinders")

# Observations from the boxplots:
# - Cars with mpg01 = 1 (more fuel-efficient) generally have:
#   * Lower horsepower
#   * Lower weight
#   * Lower displacement
#   * Fewer cylinders
#   * Newer model years
#   * Slightly higher acceleration
#
# - In contrast, cars with mpg01 = 0 tend to have higher horsepower, weight,
#   displacement, more cylinders, and older model years.

# (C)
# We select the variables that seemed most associated with mpg01 in (b).
vars <- c("mpg01", "horsepower", "weight", "displacement", 
          "cylinders", "year", "acceleration")

Auto_sub <- Auto[, vars]

# Set seed for reproducibility
set.seed(123)

# Calculate the number of rows in the data set
n <- nrow(Auto_sub)

# Randomly select 70% of the indexes as the training set
train_idx <- sample(seq_len(n), size = 0.7 * n)

# Split the dataset into a training set and a test set
train_data <- Auto_sub[train_idx, ]
test_data  <- Auto_sub[-train_idx, ]

# (d)
library(MASS)

# Fit the LDA model on the training data using selected predictors
lda_fit <- lda(mpg01 ~ horsepower + weight + displacement + cylinders + 
                 year + acceleration,
               data = train_data)

# Display the LDA model results (prior probabilities, group means, etc.)
print(lda_fit)

# Use the fitted LDA model to predict mpg01 on the test data
lda_pred <- predict(lda_fit, test_data)

# Create a confusion matrix comparing the 
# predicted classes to the actual classes
confusion_matrix <- table(lda_pred$class, test_data$mpg01)
print(confusion_matrix)

# Calculate the overall test accuracy
accuracy <- mean(lda_pred$class == test_data$mpg01)
print(paste("Test set accuracy:", round(accuracy, 4)))


# Calculate the test error as 1 minus the accuracy
# Test error represents the proportion of misclassified 
# observations in the test set.
test_error <- 1 - accuracy
print(paste("Test set error:", round(test_error, 4)))

# (e)
# Fit the QDA model on the training data using the same predictors as in LDA
qda_fit <- qda(mpg01 ~ horsepower + weight + displacement + cylinders 
               + year + acceleration,
               data = train_data)

# Display the QDA model results
print(qda_fit)

# Use the fitted QDA model to predict mpg01 on the test data
qda_pred <- predict(qda_fit, test_data)

# Create a confusion matrix comparing the predicted 
# classes to the actual classes
confusion_matrix_qda <- table(qda_pred$class, test_data$mpg01)
print(confusion_matrix_qda)

# Calculate the overall test accuracy for the QDA model
accuracy_qda <- mean(qda_pred$class == test_data$mpg01)
print(paste("Test set accuracy for QDA:", round(accuracy_qda, 4)))

# Calculate the test error for QDA
test_error_qda <- 1 - accuracy_qda
print(paste("Test set error for QDA:", round(test_error_qda, 4)))

# (f)
# Fit a logistic regression model on the training data
# 'family = binomial' indicates a binary logistic regression.
glm_fit <- glm(mpg01 ~ horsepower + weight + displacement 
               + cylinders + year + acceleration,
               data = train_data, family = binomial)

# Display a summary of the fitted logistic regression model
summary(glm_fit)

# Predict probabilities for the test data
# 'type = "response"' returns the probability of mpg01 = 1
glm_probs <- predict(glm_fit, test_data, type = "response")

# Convert predicted probabilities to binary classes (0 or 1) using a 0.5 cutoff
glm_pred <- ifelse(glm_probs > 0.5, 1, 0)

# Create a confusion matrix to compare predicted classes with actual mpg01
confusion_matrix_logistic <- table(glm_pred, test_data$mpg01)
print(confusion_matrix_logistic)

# Calculate the accuracy on the test set
accuracy_logistic <- mean(glm_pred == test_data$mpg01)
print(paste("Test set accuracy for Logistic Regression:", 
            round(accuracy_logistic, 4)))

# Calculate the test error as 1 minus the accuracy
test_error_logistic <- 1 - accuracy_logistic
print(paste("Test set error for Logistic Regression:", 
            round(test_error_logistic, 4)))

# (g)
# Load the e1071 package for the naive Bayes function
library(e1071)

# Fit the Naive Bayes model on the training data using selected predictors
nb_fit <- naiveBayes(mpg01 ~ horsepower + weight + displacement 
                     + cylinders + year + acceleration,
                     data = train_data)

# Use the fitted Naive Bayes model to predict mpg01 on the test data
nb_pred <- predict(nb_fit, test_data)

# Create a confusion matrix comparing the 
# predicted classes to the actual classes
confusion_matrix_nb <- table(nb_pred, test_data$mpg01)
print(confusion_matrix_nb)

# Calculate the overall test accuracy for the Naive Bayes model
accuracy_nb <- mean(nb_pred == test_data$mpg01)
print(paste("Test set accuracy for Naive Bayes:", round(accuracy_nb, 4)))

# Calculate the test error as 1 minus the accuracy
# Test error represents the proportion 
# of misclassified observations in the test set.
test_error_nb <- 1 - accuracy_nb
print(paste("Test set error for Naive Bayes:", round(test_error_nb, 4)))

# (h)
# Load the 'class' package for the knn() function
library(class)

# Extract the predictors (the variables most associated with mpg01 in (b))
predictors <- c("horsepower", "weight", "displacement", "cylinders", "year", "acceleration")
train.X <- train_data[, predictors]
test.X  <- test_data[, predictors]

# Define the response variables for training and test sets
train.Y <- train_data$mpg01
test.Y  <- test_data$mpg01

# Define the values of k to try
k_values <- c(1, 3, 5, 7, 9)

# Create a vector to store test errors for each k
test_errors <- numeric(length(k_values))
names(test_errors) <- k_values

# Loop over the defined k values to perform KNN and calculate test error
for (i in 1:length(k_values)) {
  k <- k_values[i]
  set.seed(123)  # Ensure reproducibility for each k
  knn_pred <- knn(train.X, test.X, train.Y, k = k)
  
  # Compute the test set accuracy and error
  accuracy_knn <- mean(knn_pred == test.Y)
  error_knn <- 1 - accuracy_knn
  
  test_errors[i] <- error_knn
  
  cat("For k =", k, ": Test set accuracy =", round(accuracy_knn, 4),
      ", Test set error =", round(error_knn, 4), "\n")
}

# Print out the test errors for all tried k values
print(test_errors)
```

